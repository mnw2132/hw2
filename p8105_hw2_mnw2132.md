p8105_hw2_mnw2132
================
Mary Williams
2024-09-30

## Problem 1

*Bring data in*

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
transit_data = read_csv(file = "/Users/nickywilliams/Desktop/hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na=c(".","NA","")) %>%
  janitor::clean_names()
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

*Read and clean data *

``` r
transit_data_clean=
select(transit_data, line, station_location, station_name, station_latitude,  station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%

mutate(
  entry = case_match(
    entry,
    "YES" ~ 1,
    "NO" ~ 0))
```

*Paragraph about the data*

After cleaning the data, it contains 20 variables, including
transit_data, line, station_location, station_name, station_latitude,
station_longitude, entry, vending, entrance_type, ada, and all 11
variables starting with route. We cleaned the data by making all missing
data represented by “na”, putting all names into snake format, selecting
the 20 variables to keep within the data, and by changing the entry
variable to a logical variable where 1=yes and 0=no. There 1,868 rows
and 20 columns in the resulting data set. Considering that the columns
are variables, the rows are observations and every value has a cell,
this data is tidy.

*How many stations*

``` r
number_stations=
  distinct(transit_data_clean, station_name, line)
number_stations
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

``` r
nrow(number_stations)
```

    ## [1] 465

Therefore, there are 465 stations in nyc.

*How many stations are ADA compliant*

``` r
ADA_stations <- transit_data_clean |>
    filter(ada=="TRUE") |>
    distinct(station_name, line) |>
nrow()

ADA_stations
```

    ## [1] 84

There are 84 ADA compliant stations.

*What proportion of entrances/exits w/out vending allow entrance*

``` r
no_vending_entry <- transit_data %>%
  filter(vending == "NO") %>%
  summarise(proportion = mean(entry == "YES"))

no_vending_entry
```

    ## # A tibble: 1 × 1
    ##   proportion
    ##        <dbl>
    ## 1      0.377

The proportion is 37.7%.

## NEED TO FINISH THIS PROBLEM

## Problem 2

``` r
library(readxl)
library(tidyverse)
#Mr. Trash Wheel
Mr_trash_wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
select(-month, -year, -date) %>%
  mutate(sports_balls = as.integer(round(sports_balls)))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
#Professor Trash Wheel
Professor_Trash_Wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() %>%
select (-month, -year) %>%
drop_na()
```

``` r
#Gwynnda
Gwynnda_Trash_Wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") %>%
  janitor::clean_names() %>%
select (-month, -year) 
```

``` r
#Combine
tidy_trash =
  bind_rows(Mr_trash_wheel, Professor_Trash_Wheel, Gwynnda_Trash_Wheel)
```

In this, there are 1030 by 14 columns. Some of the key variables include
dumpster number, weight in tons, and volume in cubic yards. For
available data, the total weight of the trash collected by Professor
Trash Wheel was 233.26 tons. Meanwhile, the number of cigarette butts
Gwynnda collected in June 2022 was 1.812^{4}.

\#Problem 3

``` r
#import and format bakers data
bakers = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/bakers.csv") %>%
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(bakers)
```

    ## # A tibble: 120 × 5
    ##    baker_name       series baker_age baker_occupation             hometown      
    ##    <chr>             <dbl>     <dbl> <chr>                        <chr>         
    ##  1 Ali Imdad             4        25 Charity worker               Saltley, Birm…
    ##  2 Alice Fevronia       10        28 Geography teacher            Essex         
    ##  3 Alvin Magallanes      6        37 Nurse                        Bracknell, Be…
    ##  4 Amelia LeBruin       10        24 Fashion designer             Halifax       
    ##  5 Andrew Smyth          7        25 Aerospace engineer           Derby / Holyw…
    ##  6 Annetha Mills         1        30 Midwife                      Essex         
    ##  7 Antony Amourdoux      9        30 Banker                       London        
    ##  8 Beca Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldershot, Ha…
    ##  9 Ben Frazer            2        31 Graphic Designer             Northampton   
    ## 10 Benjamina Ebuehi      7        23 Teaching assistant           South London  
    ## # ℹ 110 more rows

``` r
#import and format bakes data
bakes = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/bakes.csv") %>%
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(bakes)
```

    ## # A tibble: 546 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      N/A         
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… N/A         
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 536 more rows

``` r
#import and format results data 
results = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/results.csv", skip=2) %>%
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(results)
```

    ## # A tibble: 696 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jonathan          9 IN    
    ##  5      1       1 Miranda           8 IN    
    ##  6      1       1 Lea              10 OUT   
    ##  7      1       2 David             8 IN    
    ##  8      1       2 Edd               6 IN    
    ##  9      1       2 Jasminder         2 IN    
    ## 10      1       2 Jonathan          1 IN    
    ## # ℹ 686 more rows

``` r
#Make sure the columns names are both baker
colnames(bakers)[colnames(bakers) == "baker_name"] = "baker"

#Check that bakers and results have "baker" column
colnames(bakers)
```

    ## [1] "baker"            "series"           "baker_age"        "baker_occupation"
    ## [5] "hometown"

``` r
nrow(bakers)
```

    ## [1] 120

``` r
colnames(bakes)
```

    ## [1] "series"         "episode"        "baker"          "signature_bake"
    ## [5] "show_stopper"

``` r
nrow(bakes)
```

    ## [1] 548

``` r
colnames(results)
```

    ## [1] "series"    "episode"   "baker"     "technical" "result"

``` r
nrow(results)
```

    ## [1] 1136

``` r
#check how many results are not in baker 
anti_tidy_trash = anti_join(results, bakers, by = c("baker"))
all_tidy_trash = anti_join(anti_tidy_trash, bakes, by = c("baker"))
```

``` r
# combine them 
combined_data = 
  full_join(results, bakes, by = c("baker", "episode", "series")) %>%
  full_join(x = ., bakers, by = c("baker", "series")) %>%
  select(baker, series, baker_age, baker_occupation, hometown, episode, signature_bake, show_stopper, technical, result)
```

``` r
#Export as csv
write_csv(combined_data, "combined_data.csv")
```

During the data cleaning process, I imported each data set, cleaned each
set with “janitor::clean_names()” take format the titles as snake
format, and did “na.omit(…)” to remove any missing data. For results I
also did “skip=2” to remove the 1st too rows of notes, which made the
column titles the same as the other files. For bakers, I also had to
change the column name “baker_name” to “baker” so that when they are
joined, the column “baker” is same within all of the datasets. Anti-join
shows the discrepencies between the data sets. Considering that I could
not join 3 datasets all together directly, I joined results and bakers,
and then combined bakes into the combined file.

The final data set includes 1264 rows and 10 columns and has each
person’s information lined up according to each season and episode they
were in.

``` r
table_all = combined_data %>%
  filter(series >= 5 & series <= 10) %>%
  filter(result %in% c( "WINNER", "STAR BAKER")) %>%
  select(series, episode, baker, result) %>%
 distinct()
```

``` r
print(table_all)
```

    ## # A tibble: 60 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       2 Richard STAR BAKER
    ##  3      5       3 Luis    STAR BAKER
    ##  4      5       4 Richard STAR BAKER
    ##  5      5       5 Kate    STAR BAKER
    ##  6      5       6 Chetna  STAR BAKER
    ##  7      5       7 Richard STAR BAKER
    ##  8      5       8 Richard STAR BAKER
    ##  9      5       9 Richard STAR BAKER
    ## 10      5      10 Nancy   WINNER    
    ## # ℹ 50 more rows

``` r
#viewership
viewers <- read_csv("/Users/nickywilliams/Desktop/hw2/gbb_datasets/viewers.csv") %>%
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(results)
```

    ## # A tibble: 696 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jonathan          9 IN    
    ##  5      1       1 Miranda           8 IN    
    ##  6      1       1 Lea              10 OUT   
    ##  7      1       2 David             8 IN    
    ##  8      1       2 Edd               6 IN    
    ##  9      1       2 Jasminder         2 IN    
    ## 10      1       2 Jonathan          1 IN    
    ## # ℹ 686 more rows

``` r
# Show the first 10 rows
head(viewers, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
colnames(viewers)
```

    ##  [1] "episode"   "series_1"  "series_2"  "series_3"  "series_4"  "series_5" 
    ##  [7] "series_6"  "series_7"  "series_8"  "series_9"  "series_10"

``` r
season_1 <- viewers %>%
  summarize(season_1 = mean(`series_1`, na.rm = TRUE))

season_5 <- viewers %>%
  summarise(season_5 = mean(`series_5`, na.rm = TRUE))

print(season_1)
```

    ## # A tibble: 1 × 1
    ##   season_1
    ##      <dbl>
    ## 1     2.77

``` r
print(season_5)
```

    ## # A tibble: 1 × 1
    ##   season_5
    ##      <dbl>
    ## 1     10.0

The average viewership in season 1 was 2.77 and for season 5 it was
10.0.
