p8105_hw2_mnw2132
================
Mary Williams
2024-09-30

## Problem 1

*Bring data in*

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
transit_data = read_csv(file = "/Users/nickywilliams/Desktop/hw2/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na=c(".","NA","")) %>%
  janitor::clean_names()
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
transit_data
```

    ## # A tibble: 1,868 × 32
    ##    division line   station_name station_latitude station_longitude route1 route2
    ##    <chr>    <chr>  <chr>                   <dbl>             <dbl> <chr>  <chr> 
    ##  1 BMT      4 Ave… 25th St                  40.7             -74.0 R      <NA>  
    ##  2 BMT      4 Ave… 25th St                  40.7             -74.0 R      <NA>  
    ##  3 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  4 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  5 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  6 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  7 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  8 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  9 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ## 10 BMT      4 Ave… 53rd St                  40.6             -74.0 R      <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 25 more variables: route3 <chr>, route4 <chr>, route5 <chr>, route6 <chr>,
    ## #   route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entrance_type <chr>, entry <chr>, exit_only <chr>, vending <chr>,
    ## #   staffing <chr>, staff_hours <chr>, ada <lgl>, ada_notes <chr>,
    ## #   free_crossover <lgl>, north_south_street <chr>, east_west_street <chr>,
    ## #   corner <chr>, entrance_latitude <dbl>, entrance_longitude <dbl>, …

``` r
select(transit_data, line, station_location, station_name, station_latitude,  station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%

mutate(
  entry = case_match(
    entry,
    "YES" ~ 1,
    "NO" ~ 0))
```

    ## # A tibble: 1,868 × 20
    ##    line  station_location station_name station_latitude station_longitude route1
    ##    <chr> <chr>            <chr>                   <dbl>             <dbl> <chr> 
    ##  1 4 Av… (40.660397, -73… 25th St                  40.7             -74.0 R     
    ##  2 4 Av… (40.660397, -73… 25th St                  40.7             -74.0 R     
    ##  3 4 Av… (40.655144, -74… 36th St                  40.7             -74.0 N     
    ##  4 4 Av… (40.655144, -74… 36th St                  40.7             -74.0 N     
    ##  5 4 Av… (40.655144, -74… 36th St                  40.7             -74.0 N     
    ##  6 4 Av… (40.648939, -74… 45th St                  40.6             -74.0 R     
    ##  7 4 Av… (40.648939, -74… 45th St                  40.6             -74.0 R     
    ##  8 4 Av… (40.648939, -74… 45th St                  40.6             -74.0 R     
    ##  9 4 Av… (40.648939, -74… 45th St                  40.6             -74.0 R     
    ## 10 4 Av… (40.645069, -74… 53rd St                  40.6             -74.0 R     
    ## # ℹ 1,858 more rows
    ## # ℹ 14 more variables: route2 <chr>, route3 <chr>, route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entry <dbl>, vending <chr>, entrance_type <chr>, ada <lgl>

*Read and clean data *

``` r
transit_data
```

    ## # A tibble: 1,868 × 32
    ##    division line   station_name station_latitude station_longitude route1 route2
    ##    <chr>    <chr>  <chr>                   <dbl>             <dbl> <chr>  <chr> 
    ##  1 BMT      4 Ave… 25th St                  40.7             -74.0 R      <NA>  
    ##  2 BMT      4 Ave… 25th St                  40.7             -74.0 R      <NA>  
    ##  3 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  4 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  5 BMT      4 Ave… 36th St                  40.7             -74.0 N      R     
    ##  6 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  7 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  8 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ##  9 BMT      4 Ave… 45th St                  40.6             -74.0 R      <NA>  
    ## 10 BMT      4 Ave… 53rd St                  40.6             -74.0 R      <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 25 more variables: route3 <chr>, route4 <chr>, route5 <chr>, route6 <chr>,
    ## #   route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entrance_type <chr>, entry <chr>, exit_only <chr>, vending <chr>,
    ## #   staffing <chr>, staff_hours <chr>, ada <lgl>, ada_notes <chr>,
    ## #   free_crossover <lgl>, north_south_street <chr>, east_west_street <chr>,
    ## #   corner <chr>, entrance_latitude <dbl>, entrance_longitude <dbl>, …

``` r
transit_data_clean=
select(transit_data, line, station_location, station_name, station_latitude,  station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%

mutate(
  entry = case_match(
    entry,
    "YES" ~ 1,
    "NO" ~ 0))
```

*Paragraph about the data*

After cleaning the data, it contains 20 variables, including
transit_data, line, station_location, station_name, station_latitude,
station_longitude, entry, vending, entrance_type, ada, and all 11
variables starting with route. We cleaned the data by making all missing
data represented by “na”, putting all names into snake format, selecting
the 20 variables to keep within the data, and by changing the entry
variable to a logical variable where 1=yes and 0=no. There 1,868 rows
and 20 columns in the resulting data set. Considering that the columns
are variables, the rows are observations and every value has a cell,
this data is tidy.

*How many stations*

``` r
number_stations=
  distinct(transit_data_clean, station_name, line)
number_stations
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

``` r
nrow(number_stations)
```

    ## [1] 465

Therefore, there are 465 stations in nyc.

*How many stations are ADA compliant*

``` r
ADA_stations <- transit_data_clean |>
    filter(ada=="TRUE") |>
    distinct(station_name, line) |>
nrow()

ADA_stations
```

    ## [1] 84

There are 84 ADA compliant stations.

*What proportion of entrances/exits w/out vending allow entrance*

``` r
no_vending_entry <- transit_data %>%
  filter(vending == "NO") %>%
  summarise(proportion = mean(entry == "YES"))

no_vending_entry
```

    ## # A tibble: 1 × 1
    ##   proportion
    ##        <dbl>
    ## 1      0.377

The proportion is 37.7%.

## NEED TO FINISH THIS PROBLEM

## Problem 2

``` r
library(readxl)
library(tidyverse)
#Mr. Trash Wheel
Mr_trash_wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
select(-month, -year, -date) %>%
  mutate(sports_balls = as.integer(round(sports_balls)))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
#Professor Trash Wheel
Professor_Trash_Wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") %>%
  janitor::clean_names() %>%
select (-month, -year)
```

``` r
#Gwynnda
Gwynnda_Trash_Wheel = read_excel("/Users/nickywilliams/Desktop/hw2/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") %>%
  janitor::clean_names() %>%
select (-month, -year) 
```

``` r
#Combine
tidy_trash=
  bind_rows(Mr_trash_wheel, Professor_Trash_Wheel, Gwynnda_Trash_Wheel)

tidy_trash
```

    ## # A tibble: 1,038 × 14
    ##    dumpster weight_tons volume_cubic_yards plastic_bottles polystyrene
    ##       <dbl>       <dbl>              <dbl>           <dbl>       <dbl>
    ##  1        1        4.31                 18            1450        1820
    ##  2        2        2.74                 13            1120        1030
    ##  3        3        3.45                 15            2450        3100
    ##  4        4        3.1                  15            2380        2730
    ##  5        5        4.06                 18             980         870
    ##  6        6        2.71                 13            1430        2140
    ##  7        7        1.91                  8             910        1090
    ##  8        8        3.7                  16            3580        4310
    ##  9        9        2.52                 14            2400        2790
    ## 10       10        3.76                 18            1340        1730
    ## # ℹ 1,028 more rows
    ## # ℹ 9 more variables: cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, x15 <lgl>, x16 <lgl>, date <dttm>

In this, there are 1038 by 14 columns. Some of the key variables include
dumpster number, weight in tons, and volume in cubic yards. For
available data, the total weight of the trash collected by Professor
Trash Wheel was 488 tons. Meanwhile, the number of cigarette butts
Gwynnda collected in June 2022 was 1.812^{4}.

\##Problem 3

``` r
#import and format bakers data
bakers = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/bakers.csv") %>%
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(bakers)
```

    ## # A tibble: 120 × 5
    ##    baker_name       series baker_age baker_occupation             hometown      
    ##    <chr>             <dbl>     <dbl> <chr>                        <chr>         
    ##  1 Ali Imdad             4        25 Charity worker               Saltley, Birm…
    ##  2 Alice Fevronia       10        28 Geography teacher            Essex         
    ##  3 Alvin Magallanes      6        37 Nurse                        Bracknell, Be…
    ##  4 Amelia LeBruin       10        24 Fashion designer             Halifax       
    ##  5 Andrew Smyth          7        25 Aerospace engineer           Derby / Holyw…
    ##  6 Annetha Mills         1        30 Midwife                      Essex         
    ##  7 Antony Amourdoux      9        30 Banker                       London        
    ##  8 Beca Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldershot, Ha…
    ##  9 Ben Frazer            2        31 Graphic Designer             Northampton   
    ## 10 Benjamina Ebuehi      7        23 Teaching assistant           South London  
    ## # ℹ 110 more rows

``` r
#import and format bakes data
bakes = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/bakes.csv") %>%
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(bakes)
```

    ## # A tibble: 546 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      N/A         
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… N/A         
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 536 more rows

``` r
#import and format results data 
results = read_csv(file = "/Users/nickywilliams/Desktop/hw2/gbb_datasets/results.csv", skip=2) %>%
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
  na.omit(results)
```

    ## # A tibble: 696 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jonathan          9 IN    
    ##  5      1       1 Miranda           8 IN    
    ##  6      1       1 Lea              10 OUT   
    ##  7      1       2 David             8 IN    
    ##  8      1       2 Edd               6 IN    
    ##  9      1       2 Jasminder         2 IN    
    ## 10      1       2 Jonathan          1 IN    
    ## # ℹ 686 more rows

``` r
#check column names
colnames(bakers)
```

    ## [1] "baker_name"       "series"           "baker_age"        "baker_occupation"
    ## [5] "hometown"

``` r
colnames(bakes)
```

    ## [1] "series"         "episode"        "baker"          "signature_bake"
    ## [5] "show_stopper"

``` r
colnames(results)
```

    ## [1] "series"    "episode"   "baker"     "technical" "result"

``` r
#Make sure the columns names are both baker
colnames(bakers)[colnames(bakers) == "baker_name"] = "baker"

#Check that bakers and results have "baker" column
colnames(bakers)
```

    ## [1] "baker"            "series"           "baker_age"        "baker_occupation"
    ## [5] "hometown"

``` r
colnames(bakes)
```

    ## [1] "series"         "episode"        "baker"          "signature_bake"
    ## [5] "show_stopper"

``` r
colnames(results)
```

    ## [1] "series"    "episode"   "baker"     "technical" "result"

``` r
anti_tidy_trash = anti_join(results, bakers, by = c("baker"))

all_tidy_trash = anti_join(anti_tidy_trash, bakes, by = "baker")

#Export as csv
write_csv(all_tidy_trash, "all_tidy_trash.csv")
```

During the data cleaning process, I imported each data set, cleaned each
set with “janitor::clean_names()” take format the titles as snake
format, and did “na.omit(…)” to remove any missing data. For results I
also did skip=2 to remove the 1st too rows of notes, which made the
column titles the same as the other files. For bakers, I also had to
change the column name “baker_name” to “baker” so that when they are
joined, the column “baker” is same within all of the datasets.
Considering that I could not join 3 datasets all together directly, I
joined results and bakers, and then combined bakes into the combined
file.

The final data set includes 228 and 5 and has each person’s information
lined up according to each season and episode they were in.
